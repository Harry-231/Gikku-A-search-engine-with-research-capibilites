{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228ed117",
   "metadata": {},
   "source": [
    "# Search Engine with Tools and Agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d580112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6651314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73a8d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "606b255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv--Research \n",
    "\n",
    "## Tools creation \n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun , WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01f9027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Used the inbuilt tool of wikipedia \n",
    "\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results = 1 , doc_content_chars_max = 250) \n",
    "wiki = WikipediaQueryRun(api_wrapper = api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "771060fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results = 5 , doc_content_chars_max = 250)\n",
    "arxiv = ArxivQueryRun(api_wrapper = api_wrapper_arxiv)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "119e44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki , arxiv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e47be177",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making our custom tools [Rag tool] \n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "392d6cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001C284873F10>, search_kwargs={})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://cookbook.openai.com/examples/how_to_build_a_tool-using_agent_with_langchain\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size = 1000 , chunk_overlap = 200).split_documents(docs)\n",
    "vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "799cffc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain-Search'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool \n",
    "retriever_tool = create_retriever_tool(retriever , \"Langchain-Search\" , \"Search any information about how tools can be made using Langcahin\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97075105",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv , wiki , retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1461c616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=5, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\anaconda3\\\\envs\\\\lc-academy-env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='Langchain-Search', description='Search any information about how tools can be made using Langcahin', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001C2D64F8220>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001C284873F10>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001C2D64F84A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001C284873F10>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d38c6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the tools with agents and LLM Models \n",
    "\n",
    "# Tools , LLM --> AgentExecutor \n",
    "import openai\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key = groq_api_key , model_name = \"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b6fea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template \n",
    "from langchain import hub \n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a23aad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001C2D6056840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001C2D6056840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C2854D2090>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C28530C990>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Langchain-Search', 'description': 'Search any information about how tools can be made using Langcahin', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agents \n",
    "\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b7230a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent Executer \n",
    "\n",
    "from langchain.agents import AgentExecutor \n",
    "\n",
    "agent_executor = AgentExecutor(agent = agent,tools = tools , verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6f51c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001C2D6056840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001C2D6056840>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C2854D2090>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C28530C990>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Langchain-Search', 'description': 'Search any information about how tools can be made using Langcahin', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=5, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\anaconda3\\\\envs\\\\lc-academy-env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='Langchain-Search', description='Search any information about how tools can be made using Langcahin', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001C2D64F8220>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001C284873F10>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001C2D64F84A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001C284873F10>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e5c359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Langchain-Search` with `{'query': 'How to create a tool using Langchain and OpenAI'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mHow to build a tool-using agent with LangChainTopicsAboutAPI DocsSourceToggle themeToggle themeMay 2, 2023How to build a tool-using agent with LangChainColin Jarvis(OpenAI)Open in GithubView as MarkdownThis notebook takes you through how to use LangChain to augment an OpenAI model with access to external tools. In particular, you'll be able to create LLM agents that use custom tools to answer user queries.\n",
      "What is Langchain?\n",
      "LangChain is a framework for developing applications powered by language models. Their framework enables you to build layered LLM-powered applications that are context-aware and able to interact dynamically with their environment as agents, leading to simplified code for you and a more dynamic user experience for your customers.\n",
      "Why do LLMs need to use Tools?\n",
      "\n",
      "# Langchain imports\n",
      "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
      "from langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\n",
      "from langchain import SerpAPIWrapper, LLMChain\n",
      "from langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\n",
      "# LLM wrapper\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain import OpenAI\n",
      "# Conversational memory\n",
      "from langchain.memory import ConversationBufferWindowMemory\n",
      "# Embeddings and vectorstore\n",
      "from langchain.embeddings.openai import OpenAIEmbeddings\n",
      "from langchain.vectorstores import Pinecone\n",
      "\n",
      "# Vectorstore Index\n",
      "index_name = 'podcasts'For acquiring an API key to connect with Pinecone, you can set up a free account and store it in the api_key variable below or in your environment variables under PINECONE_API_KEYapi_key = os.getenv(\"PINECONE_API_KEY\") or \"PINECONE_API_KEY\"\n",
      "\n",
      "LLM Agent with Tools\n",
      "Extend our list of tools by creating a RetrievalQA chain leveraging our Pinecone knowledge base.from langchain.chains import RetrievalQA\n",
      "\n",
      "retrieval_llm = OpenAI(temperature=0)\n",
      "\n",
      "Setup: Import packages and connect to a Pinecone vector database.\n",
      "LLM Agent: Build an agent that leverages a modified version of the ReAct framework to do chain-of-thought reasoning.\n",
      "LLM Agent with History: Provide the LLM with access to previous steps in the conversation.\n",
      "Knowledge Base: Create a knowledge base of \"Stuff You Should Know\" podcast episodes, to be accessed through a tool.\n",
      "LLM Agent with Tools: Extend the agent with access to multiple tools and test that it uses them to answer questions.\n",
      "%load_ext autoreload\n",
      "%autoreload 2The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Setup\n",
      "Import libraries and set up a connection to a Pinecone vector database.\n",
      "You can substitute Pinecone for any other vectorstore or database - there are a selection that are supported by Langchain natively, while other connectors will need to be developed yourself.!pip install openai\n",
      "!pip install pinecone-client\n",
      "!pip install pandas\n",
      "!pip install typing\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'How to create a tool using Langchain and OpenAI'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2023-12-05\n",
      "Title: Breast Ultrasound Report Generation using LangChain\n",
      "Authors: Jaeyoung Huh, Hyun Jeong Park, Jong Chul Ye\n",
      "Summary: Breast ultrasound (BUS) is a critical diagnostic tool in the field of breast\n",
      "imaging, aiding in the early d\u001b[0m\u001b[32;1m\u001b[1;3mBased on the results of the previous tool calls, it appears that you are interested in learning how to create a tool using Langchain and OpenAI. The second tool call yielded information on a research paper that discusses the use of Langchain for generating breast ultrasound reports. This suggests that Langchain has the potential to be used in various applications, including healthcare.\n",
      "\n",
      "To answer your original question, creating a tool using Langchain and OpenAI involves several steps. First, you need to import the necessary libraries and set up a connection to a Pinecone vector database. Then, you can build an LLM agent that leverages a modified version of the ReAct framework to do chain-of-thought reasoning. You can also provide the LLM with access to previous steps in the conversation and create a knowledge base of relevant information.\n",
      "\n",
      "Here is an example of how you can create a simple tool using Langchain and OpenAI:\n",
      "```\n",
      "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
      "from langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\n",
      "from langchain import SerpAPIWrapper, LLMChain\n",
      "from langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\n",
      "\n",
      "# Set up the LLM agent\n",
      "llm = OpenAI(temperature=0)\n",
      "\n",
      "# Set up the tool\n",
      "tool = Tool(llm, \"arxiv\")\n",
      "\n",
      "# Set up the agent executor\n",
      "agent_executor = AgentExecutor(tool)\n",
      "\n",
      "# Set up the agent output parser\n",
      "agent_output_parser = AgentOutputParser()\n",
      "\n",
      "# Define the prompt template\n",
      "prompt_template = BaseChatPromptTemplate(\"What is the latest research on breast ultrasound?\")\n",
      "\n",
      "# Define the chat prompt\n",
      "chat_prompt = ChatPromptTemplate(prompt_template)\n",
      "\n",
      "# Execute the agent\n",
      "agent = LLMSingleActionAgent(agent_executor, agent_output_parser)\n",
      "agent.execute(chat_prompt)\n",
      "\n",
      "# Get the output\n",
      "output = agent.get_output()\n",
      "\n",
      "# Print the output\n",
      "print(output)\n",
      "```\n",
      "This code creates an LLM agent that uses the arxiv tool to answer a question about the latest research on breast ultrasound. The output of the agent is then printed to the console.\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about how to create a tools using langchain and openai',\n",
       " 'output': 'Based on the results of the previous tool calls, it appears that you are interested in learning how to create a tool using Langchain and OpenAI. The second tool call yielded information on a research paper that discusses the use of Langchain for generating breast ultrasound reports. This suggests that Langchain has the potential to be used in various applications, including healthcare.\\n\\nTo answer your original question, creating a tool using Langchain and OpenAI involves several steps. First, you need to import the necessary libraries and set up a connection to a Pinecone vector database. Then, you can build an LLM agent that leverages a modified version of the ReAct framework to do chain-of-thought reasoning. You can also provide the LLM with access to previous steps in the conversation and create a knowledge base of relevant information.\\n\\nHere is an example of how you can create a simple tool using Langchain and OpenAI:\\n```\\nfrom langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\\nfrom langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\\nfrom langchain import SerpAPIWrapper, LLMChain\\nfrom langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\\n\\n# Set up the LLM agent\\nllm = OpenAI(temperature=0)\\n\\n# Set up the tool\\ntool = Tool(llm, \"arxiv\")\\n\\n# Set up the agent executor\\nagent_executor = AgentExecutor(tool)\\n\\n# Set up the agent output parser\\nagent_output_parser = AgentOutputParser()\\n\\n# Define the prompt template\\nprompt_template = BaseChatPromptTemplate(\"What is the latest research on breast ultrasound?\")\\n\\n# Define the chat prompt\\nchat_prompt = ChatPromptTemplate(prompt_template)\\n\\n# Execute the agent\\nagent = LLMSingleActionAgent(agent_executor, agent_output_parser)\\nagent.execute(chat_prompt)\\n\\n# Get the output\\noutput = agent.get_output()\\n\\n# Print the output\\nprint(output)\\n```\\nThis code creates an LLM agent that uses the arxiv tool to answer a question about the latest research on breast ultrasound. The output of the agent is then printed to the console.\\n\\nI hope this helps! Let me know if you have any further questions.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Tell me about how to create a tools using langchain and openai\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bb2519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Generative Adversarial Networks'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Generative adversarial network\n",
      "Summary: A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative artificial intelligence. The concept was initially developed by Ian Go\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Generative Adversarial Networks'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2018-10-30\n",
      "Title: Improved Network Robustness with Adversary Critic\n",
      "Authors: Alexander Matyasko, Lap-Pui Chau\n",
      "Summary: Ideally, what confuses neural network should be confusing to humans. However,\n",
      "recent experiments have shown that small, \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Langchain-Search` with `{'query': 'what is generative adversarial network used for'}`\n",
      "responded: Based on the information provided, it appears that the user is interested in learning more about Generative Adversarial Networks (GANs). To provide a more comprehensive answer, I will use the tools to gather more information and then respond with a direct answer.\n",
      "\n",
      "The Wikipedia page provided a good summary of GANs, and the arXiv paper provided a more technical perspective on the topic. However, to provide a more complete answer, I would like to use the \"Langchain-Search\" tool to search for more information.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mHow to build a tool-using agent with LangChainTopicsAboutAPI DocsSourceToggle themeToggle themeMay 2, 2023How to build a tool-using agent with LangChainColin Jarvis(OpenAI)Open in GithubView as MarkdownThis notebook takes you through how to use LangChain to augment an OpenAI model with access to external tools. In particular, you'll be able to create LLM agents that use custom tools to answer user queries.\n",
      "What is Langchain?\n",
      "LangChain is a framework for developing applications powered by language models. Their framework enables you to build layered LLM-powered applications that are context-aware and able to interact dynamically with their environment as agents, leading to simplified code for you and a more dynamic user experience for your customers.\n",
      "Why do LLMs need to use Tools?\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\"Zoos can have both positive and negative effects on animals, but they can play a role in conservation efforts for endangered species. It's important to consider both sides of the argument and do research before forming an opinion.\"You now have a template to deploy conversational agents with tools. If you want to extend this with a Custom Agent to add your own retry behaviour or treatment of input/output variables, then follow this article.\n",
      "We look forward to seeing what you build!\n",
      "\n",
      "Why do LLMs need to use Tools?\n",
      "One of the most common challenges with LLMs is overcoming the lack of recency and specificity in their training data - answers can be out of date, and they are prone to hallucinations given the huge variety in their knowledge base. Tools are a great method of allowing an LLM to answer within a controlled context that draws on your existing knowledge bases and internal APIs - instead of trying to prompt engineer the LLM all the way to your intended answer, you allow it access to tools that it calls on dynamically for info, parses, and serves to customer.\n",
      "\n",
      "Providing LLMs access to tools can enable them to answer questions with context directly from search engines, APIs or your own databases. Instead of answering directly, an LLM with access to tools can perform intermediate steps to gather relevant information. Tools can also be used in combination. For example, a language model can be made to use a search tool to lookup quantitative information and a calculator to execute calculations.\n",
      "Notebook Sections\u001b[0m\u001b[32;1m\u001b[1;3mThank you for providing the results of the previous tool calls. Based on the outputs, it seems that LangChain is a framework for developing applications powered by language models, and it allows LLMs to interact dynamically with their environment using tools.\n",
      "\n",
      "Considering the conversation about Generative Adversarial Networks (GANs), I'd like to provide a direct response. GANs are a type of deep learning framework that uses a combination of a generator and discriminator to generate new, synthetic data that resembles existing data. This technique has been applied to various domains, including computer vision, natural language processing, and audio processing.\n",
      "\n",
      "In the context of GANs, tools like Wikipedia and ArXiv can be used to gather information about the concept, its applications, and its limitations. Additionally, LangChain can be used to augment an LLM-powered application with access to external tools, enabling the model to interact dynamically with its environment and answer more complex questions.\n",
      "\n",
      "Please let me know if you have any further questions or if there's anything else I can assist you with.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what is GAN's\",\n",
       " 'output': \"Thank you for providing the results of the previous tool calls. Based on the outputs, it seems that LangChain is a framework for developing applications powered by language models, and it allows LLMs to interact dynamically with their environment using tools.\\n\\nConsidering the conversation about Generative Adversarial Networks (GANs), I'd like to provide a direct response. GANs are a type of deep learning framework that uses a combination of a generator and discriminator to generate new, synthetic data that resembles existing data. This technique has been applied to various domains, including computer vision, natural language processing, and audio processing.\\n\\nIn the context of GANs, tools like Wikipedia and ArXiv can be used to gather information about the concept, its applications, and its limitations. Additionally, LangChain can be used to augment an LLM-powered application with access to external tools, enabling the model to interact dynamically with its environment and answer more complex questions.\\n\\nPlease let me know if you have any further questions or if there's anything else I can assist you with.\"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is GAN's\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ff474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
